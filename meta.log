Parsing starts at: Sun Nov  6 22:13:24 2022
s1, 1, INFO dfs.DataNode$PacketResponder: PacketResponder <*it> for block blk_<*it> terminating
s1, 2, INFO dfs.DataNode$PacketResponder: PacketResponder <*it> for block blk_<*it> terminating
s2, 3, INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: <*ip> is added to blk_<*it> size <*it>
s1, 4, INFO dfs.DataNode$PacketResponder: PacketResponder <*it> for block blk_<*it> terminating
m1, 5, Traceback (most recent call last):
m1, 9, Traceback (most recent call last):
m1, 14, Traceback (most recent call last):
m1, 19, Traceback (most recent call last):
s3, 22, <*it> <*it> <*it> INFO dfs.DataNode$PacketResponder: PacketResponder <*it> for block blk_<*it> terminating
t1, 24, PID USER PR NI VIRT RES SHR ST %CPU %MEM TIME+ COMMAND
s2, 47, INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: <*ip> is added to blk_<*it> size <*it>
s2, 48, INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: <*ip> is added to blk_<*it> size <*it>
m2, 50, <*it><?><*it><?><*it> <*it>:<*it>:<*it>,<*it> ERROR [http<?>nio<?><*it><?>exec<?><*it>] classOne: Index out of range
s2, 63, INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: <*ip> is added to blk_<*it> size <*it>
s1, 64, INFO dfs.DataNode$PacketResponder: PacketResponder <*it> for block blk_<*it> terminating
t2, 65,  event_time  user_host  thread_id  server_id  command_type  argument 
s4, 78, INFO dfs.DataNode$PacketResponder: Received block blk_<*it> of size <*it> from <*ip>
s4, 79, INFO dfs.DataNode$PacketResponder: Received block blk_<*it> of size <*it> from <*ip>
m1, 80, Traceback (most recent call last):
s5, 88, INFO client.AHSProxy: Connecting to Application History server at manager.cuhk.com<*ip>
s6, 89, INFO hdfs.DFSClient: Created token for team7: HDFS_DELEGATION_TOKEN owner<?>team7@BIGDATA, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it> on ha<?>hdfs:cuhkcluster
s7, 90, INFO kms.KMSClientProvider: Getting new token from http:<*dr> renewer:rm<*dr>
s8, 91, INFO kms.KMSClientProvider: New token received: (Kind: kms<?>dt, Service: <*ip>, Ident: (kms<?>dt owner<?>team7, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it>))
s9, 92, INFO security.TokenCache: Got dt for hdfs:<*dr> Kind: HDFS_DELEGATION_TOKEN, Service: ha<?>hdfs:cuhkcluster, Ident: (token for team7: HDFS_DELEGATION_TOKEN owner<?>team7@BIGDATA, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it>)
s10, 93, INFO security.TokenCache: Got dt for hdfs:<*dr> Kind: kms<?>dt, Service: <*ip>, Ident: (kms<?>dt owner<?>team7, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it>)
s11, 94, INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: <*dr>
s12, 95, INFO input.FileInputFormat: Total input files to process : <*it>
s13, 96, INFO mapreduce.JobSubmitter: number of splits:<*it>
s14, 97, INFO mapreduce.JobSubmitter: Submitting tokens for job: job_<*it>_<*it>
s15, 98, INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha<?>hdfs:cuhkcluster, Ident: (token for team7: HDFS_DELEGATION_TOKEN owner<?>team7@BIGDATA, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it>), Kind: kms<?>dt, Service: <*ip>, Ident: (kms<?>dt owner<?>team7, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it>)]
s16, 99, INFO conf.Configuration: found resource resource<?>types.xml at file:<*dr>
s17, 100, INFO impl.TimelineClientImpl: Timeline service address: manager.cuhk.com:<*it>
s18, 101, INFO impl.YarnClientImpl: Submitted application application_<*it>_<*it>
s19, 102, INFO mapreduce.Job: The url to track the job: http:<*dr>
s20, 103, INFO mapreduce.Job: Running job: job_<*it>_<*it>
s21, 104, INFO mapreduce.Job: Job job_<*it>_<*it> running in uber mode : <*bl>
s22, 105, INFO mapreduce.Job: map <*it>% reduce <*it>%
s22, 106, INFO mapreduce.Job: map <*it>% reduce <*it>%
s23, 107, INFO mapreduce.Job: Job job_<*it>_<*it> completed successfully
m3, 108, INFO mapreduce.Job: Counters: <*it>
m4, 154, INFO client.AHSProxy: Connecting to Application History server at manager.cuhk.com<*ip>
s5, 157, INFO client.AHSProxy: Connecting to Application History server at manager.cuhk.com<*ip>
s6, 158, INFO hdfs.DFSClient: Created token for team7: HDFS_DELEGATION_TOKEN owner<?>team7@BIGDATA, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it> on ha<?>hdfs:cuhkcluster
s7, 159, INFO kms.KMSClientProvider: Getting new token from http:<*dr> renewer:rm<*dr>
s8, 160, INFO kms.KMSClientProvider: New token received: (Kind: kms<?>dt, Service: <*ip>, Ident: (kms<?>dt owner<?>team7, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it>))
s9, 161, INFO security.TokenCache: Got dt for hdfs:<*dr> Kind: HDFS_DELEGATION_TOKEN, Service: ha<?>hdfs:cuhkcluster, Ident: (token for team7: HDFS_DELEGATION_TOKEN owner<?>team7@BIGDATA, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it>)
s10, 162, INFO security.TokenCache: Got dt for hdfs:<*dr> Kind: kms<?>dt, Service: <*ip>, Ident: (kms<?>dt owner<?>team7, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it>)
s11, 163, INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: <*dr>
s13, 164, INFO mapreduce.JobSubmitter: number of splits:<*it>
s14, 165, INFO mapreduce.JobSubmitter: Submitting tokens for job: job_<*it>_<*it>
s15, 166, INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha<?>hdfs:cuhkcluster, Ident: (token for team7: HDFS_DELEGATION_TOKEN owner<?>team7@BIGDATA, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it>), Kind: kms<?>dt, Service: <*ip>, Ident: (kms<?>dt owner<?>team7, renewer<?>yarn, realUser<?>, issueDate<?><*it>, maxDate<?><*it>, sequenceNumber<?><*it>, masterKeyId<?><*it>)]
s16, 167, INFO conf.Configuration: found resource resource<?>types.xml at file:<*dr>
s17, 168, INFO impl.TimelineClientImpl: Timeline service address: manager.cuhk.com:<*it>
s18, 169, INFO impl.YarnClientImpl: Submitted application application_<*it>_<*it>
s19, 170, INFO mapreduce.Job: The url to track the job: http:<*dr>
s20, 171, INFO mapreduce.Job: Running job: job_<*it>_<*it>
s21, 172, INFO mapreduce.Job: Job job_<*it>_<*it> running in uber mode : <*bl>
s22, 173, INFO mapreduce.Job: map <*it>% reduce <*it>%
m5, 174, INFO mapreduce.Job: Task Id : attempt_<*it>_<*it>_m_<*it>_<*it>, Status : FAILED
m5, 248, INFO mapreduce.Job: Task Id : attempt_<*it>_<*it>_m_<*it>_<*it>, Status : FAILED
m5, 322, INFO mapreduce.Job: Task Id : attempt_<*it>_<*it>_m_<*it>_<*it>, Status : FAILED
s22, 396, INFO mapreduce.Job: map <*it>% reduce <*it>%
m6, 397, INFO mapreduce.Job: Job job_<*it>_<*it> failed with state FAILED due to: Task failed task_<*it>_<*it>_m_<*it>
m3, 400, INFO mapreduce.Job: Counters: <*it>
t3, 413, Type Date Time Input_data_size Duration(s) Throughput(bytes/s) Throughput/node
