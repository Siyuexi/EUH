[17:18:24] INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_38865049064139660 terminating
[17:18:24] INFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_-6952295868487656571 terminating
[17:18:24] INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.73.220:50010 is added to blk_7128370237687728475 size 67108864
[17:18:24] INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_8229193803249955061 terminating
[17:18:24] Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
IndexError: list index out of range

[17:18:24] Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
KeyError: 'a'


[17:18:24] Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ModuleNotFoundError: No module named 'nonexistmodule'


[17:18:24] Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'm' is not defined
[17:18:24] 081109 204106 329 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-6670958622368987959 terminating

[17:18:24]     PID USER      PR  NI    VIRT    RES    SHR ST  %CPU  %MEM     TIME+ COMMAND       
1708287 mqy       20   0   10.3g 904720  15404 R 102.0   0.9  11482:46 node          
1252859 wwmm      20   0   68.1g   7.6g   1.2g R 100.0   8.0  92:49.17 python        
1244584 wwmm      20   0   63.5g   7.4g   1.2g S  99.7   7.8 146:48.04 python        
1260453 root      20   0       0      0      0 R   3.3   0.0   0:00.50 kworker/u258+ 
2787694 yyl       20   0   83856  48684   2996 S   2.3   0.0 356:11.47 nvidia-smi    
1264978 xjjl      20   0  980684 150724  36076 S   1.3   0.2   0:21.94 node          
1265260 xjjl      20   0   16876   6016   3400 R   1.0   0.0   0:00.27 top           
   2328 root      20   0 4090664  22644   5744 S   0.7   0.0 122:43.57 containerd    
1038211 hyy       20   0 1074532 204272  34892 S   0.7   0.2   1:45.32 node          
1605622 skyfall   20   0 1183740  83588  18484 S   0.7   0.1 101:15.58 node          
1605675 skyfall   20   0 1058676 183600  26408 S   0.7   0.2  37:24.42 node          
1776992 mysql     20   0 2388724 390160   6480 S   0.7   0.4  44:23.74 mysqld        
     15 root      20   0       0      0      0 I   0.3   0.0  37:33.60 rcu_sched     
   2958 root     -51   0       0      0      0 S   0.3   0.0   4:56.91 irq/327-nvid+ 
 813736 root      20   0       0      0      0 I   0.3   0.0   0:22.73 kworker/4:1-+ 
 889796 hyy       20   0   13.0g  64072   8936 S   0.3   0.1  12:52.16 java          
 987212 root      20   0       0      0      0 I   0.3   0.0   0:49.15 kworker/0:0-+ 
1147262 root      20   0       0      0      0 I   0.3   0.0   0:06.62 kworker/7:2-+ 
1212042 root      20   0       0      0      0 I   0.3   0.0   0:01.96 kworker/57:2+ 
1247362 hyy       20   0   14020   6108   4504 S   0.3   0.0   0:06.77 sshd          
1247415 jiaqi     20   0   21.3g 278592  44816 S   0.3   0.3   0:24.37 node   

[17:18:24] INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.43.115:50010 is added to blk_3050920587428079149 size 67108864
[17:18:24] INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.203.80:50010 is added to blk_7888946331804732825 size 67108864

[17:18:24] 2019-08-14 14:51:22,299 ERROR [http-nio-8080-exec-8] classOne: Index out of range
java.lang.StringIndexOutOfBoundsException: String index out of range: 18
    at java.lang.String.charAt(String.java:658)
	at com.example.app.loggingApp.classOne.getResult(classOne.java:15)
	at com.example.app.loggingApp.AppController.tester(AppController.java:27)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
[...]

[17:18:24] INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.250.11.85:50010 is added to blk_2377150260128098806 size 67108864
[17:18:24] INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_572492839287299681 terminating
[17:18:24] mysql> select * from mysql.general_log;
+---------------------+---------------------------+-----------+-----------+--------------+----------------------------------+
| event_time          | user_host                 | thread_id | server_id | command_type | argument                         |
+---------------------+---------------------------+-----------+-----------+--------------+----------------------------------+
| 2017-07-06 12:32:05 | root[root] @ localhost [] |         1 |         1 | Query        | show variables like 'general%'   |
| 2017-07-06 12:32:28 | root[root] @ localhost [] |         1 |         1 | Query        | show variables like 'log_output' |
| 2017-07-06 12:32:41 | root[root] @ localhost [] |         1 |         1 | Query        | select * from MyDB.test          |
| 2017-07-06 12:34:36 | [root] @ localhost []     |         3 |         1 | Connect      | root@localhost on                |
| 2017-07-06 12:34:36 | root[root] @ localhost [] |         3 |         1 | Query        | KILL QUERY 1                     |
| 2017-07-06 12:34:36 | root[root] @ localhost [] |         3 |         1 | Quit         |                                  |
| 2017-07-06 12:34:51 | root[root] @ localhost [] |         1 |         1 | Query        | select * from mysql.general_log  |
+---------------------+---------------------------+-----------+-----------+--------------+----------------------------------+
7 rows in set (0.02 sec)
[17:18:24] INFO dfs.DataNode$PacketResponder: Received block blk_3587508140051953248 of size 67108864 from /10.251.42.84
[17:18:24] INFO dfs.DataNode$PacketResponder: Received block blk_5402003568334525940 of size 67108864 from /10.251.214.112
[17:18:24] Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 3, in demo
  File "<stdin>", line 3, in demo
  File "<stdin>", line 3, in demo
  [Previous line repeated 995 more times]
  File "<stdin>", line 2, in demo
RecursionError: maximum recursion depth exceeded in comparison
[17:18:24] INFO client.AHSProxy: Connecting to Application History server at manager.cuhk.com/10.26.10.201:10200
[17:18:24] INFO hdfs.DFSClient: Created token for team7: HDFS_DELEGATION_TOKEN owner=team7@BIGDATA, renewer=yarn, realUser=, issueDate=1667650818147, maxDate=1668255618147, sequenceNumber=8389237, masterKeyId=1027 on ha-hdfs:cuhkcluster
[17:18:24] INFO kms.KMSClientProvider: Getting new token from http://manager.cuhk.com:9292/kms/v1/, renewer:rm/master1.cuhk.com@BIGDATA
[17:18:24] INFO kms.KMSClientProvider: New token received: (Kind: kms-dt, Service: 10.26.10.201:9292, Ident: (kms-dt owner=team7, renewer=yarn, realUser=, issueDate=1667650818231, maxDate=1668255618231, sequenceNumber=64564, masterKeyId=638))
[17:18:24] INFO security.TokenCache: Got dt for hdfs://cuhkcluster; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:cuhkcluster, Ident: (token for team7: HDFS_DELEGATION_TOKEN owner=team7@BIGDATA, renewer=yarn, realUser=, issueDate=1667650818147, maxDate=1668255618147, sequenceNumber=8389237, masterKeyId=1027)
[17:18:24] INFO security.TokenCache: Got dt for hdfs://cuhkcluster; Kind: kms-dt, Service: 10.26.10.201:9292, Ident: (kms-dt owner=team7, renewer=yarn, realUser=, issueDate=1667650818231, maxDate=1668255618231, sequenceNumber=64564, masterKeyId=638)
[17:18:24] INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/team7/.staging/job_1667571544727_0240
[17:18:24] INFO input.FileInputFormat: Total input files to process : 0
[17:18:24] INFO mapreduce.JobSubmitter: number of splits:0
[17:18:24] INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1667571544727_0240
[17:18:24] INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:cuhkcluster, Ident: (token for team7: HDFS_DELEGATION_TOKEN owner=team7@BIGDATA, renewer=yarn, realUser=, issueDate=1667650818147, maxDate=1668255618147, sequenceNumber=8389237, masterKeyId=1027), Kind: kms-dt, Service: 10.26.10.201:9292, Ident: (kms-dt owner=team7, renewer=yarn, realUser=, issueDate=1667650818231, maxDate=1668255618231, sequenceNumber=64564, masterKeyId=638)]
[17:18:24] INFO conf.Configuration: found resource resource-types.xml at file:/usr/hdp/3.0.1.0-187/hadoop/etc/hadoop/resource-types.xml
[17:18:24] INFO impl.TimelineClientImpl: Timeline service address: manager.cuhk.com:8188
[17:18:24] INFO impl.YarnClientImpl: Submitted application application_1667571544727_0240
[17:18:24] INFO mapreduce.Job: The url to track the job: http://master1.cuhk.com:8088/proxy/application_1667571544727_0240/
[17:18:24] INFO mapreduce.Job: Running job: job_1667571544727_0240
[17:18:24] INFO mapreduce.Job: Job job_1667571544727_0240 running in uber mode : false
[17:18:24] INFO mapreduce.Job:  map 0% reduce 0%
[17:18:24] INFO mapreduce.Job:  map 0% reduce 100%
[17:18:24] INFO mapreduce.Job: Job job_1667571544727_0240 completed successfully
[17:18:24] INFO mapreduce.Job: Counters: 40
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=248107
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=85
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters
		Launched reduce tasks=1
		Total time spent by all maps in occupied slots (ms)=0
		Total time spent by all reduces in occupied slots (ms)=26262
		Total time spent by all reduce tasks (ms)=4377
		Total vcore-milliseconds taken by all reduce tasks=4377
		Total megabyte-milliseconds taken by all reduce tasks=26892288
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=0
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=88
		CPU time spent (ms)=1010
		Physical memory (bytes) snapshot=329465856
		Virtual memory (bytes) snapshot=7376781312
		Total committed heap usage (bytes)=552075264
		Peak Reduce Physical memory (bytes)=329465856
		Peak Reduce Virtual memory (bytes)=7376781312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters
		Bytes Written=85
[17:18:24] INFO client.AHSProxy: Connecting to Application History server at manager.cuhk.com/10.26.10.201:10200
Running 1 maps.
Job started: Sat Nov 05 20:12:19 CST 2022
[17:18:24] INFO client.AHSProxy: Connecting to Application History server at manager.cuhk.com/10.26.10.201:10200
[17:18:24] INFO hdfs.DFSClient: Created token for team7: HDFS_DELEGATION_TOKEN owner=team7@BIGDATA, renewer=yarn, realUser=, issueDate=1667650611231, maxDate=1668255411231, sequenceNumber=8389215, masterKeyId=1027 on ha-hdfs:cuhkcluster
[17:18:24] INFO kms.KMSClientProvider: Getting new token from http://manager.cuhk.com:9292/kms/v1/, renewer:rm/master1.cuhk.com@BIGDATA
[17:18:24] INFO kms.KMSClientProvider: New token received: (Kind: kms-dt, Service: 10.26.10.201:9292, Ident: (kms-dt owner=team7, renewer=yarn, realUser=, issueDate=1667650611347, maxDate=1668255411347, sequenceNumber=64563, masterKeyId=638))
[17:18:24] INFO security.TokenCache: Got dt for hdfs://cuhkcluster; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:cuhkcluster, Ident: (token for team7: HDFS_DELEGATION_TOKEN owner=team7@BIGDATA, renewer=yarn, realUser=, issueDate=1667650611231, maxDate=1668255411231, sequenceNumber=8389215, masterKeyId=1027)
[17:18:24] INFO security.TokenCache: Got dt for hdfs://cuhkcluster; Kind: kms-dt, Service: 10.26.10.201:9292, Ident: (kms-dt owner=team7, renewer=yarn, realUser=, issueDate=1667650611347, maxDate=1668255411347, sequenceNumber=64563, masterKeyId=638)
[17:18:24] INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/team7/.staging/job_1667571544727_0239
[17:18:24] INFO mapreduce.JobSubmitter: number of splits:1
[17:18:24] INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1667571544727_0239
[17:18:24] INFO mapreduce.JobSubmitter: Executing with tokens: [Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:cuhkcluster, Ident: (token for team7: HDFS_DELEGATION_TOKEN owner=team7@BIGDATA, renewer=yarn, realUser=, issueDate=1667650611231, maxDate=1668255411231, sequenceNumber=8389215, masterKeyId=1027), Kind: kms-dt, Service: 10.26.10.201:9292, Ident: (kms-dt owner=team7, renewer=yarn, realUser=, issueDate=1667650611347, maxDate=1668255411347, sequenceNumber=64563, masterKeyId=638)]
[17:18:24] INFO conf.Configuration: found resource resource-types.xml at file:/usr/hdp/3.0.1.0-187/hadoop/etc/hadoop/resource-types.xml
[17:18:24] INFO impl.TimelineClientImpl: Timeline service address: manager.cuhk.com:8188
[17:18:24] INFO impl.YarnClientImpl: Submitted application application_1667571544727_0239
[17:18:24] INFO mapreduce.Job: The url to track the job: http://master1.cuhk.com:8088/proxy/application_1667571544727_0239/
[17:18:24] INFO mapreduce.Job: Running job: job_1667571544727_0239
[17:18:24] INFO mapreduce.Job: Job job_1667571544727_0239 running in uber mode : false
[17:18:24] INFO mapreduce.Job:  map 0% reduce 0%
[17:18:24] INFO mapreduce.Job: Task Id : attempt_1667571544727_0239_m_000000_0, Status : FAILED
Error: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /dataspace/team7 is exceeded: quota = 10737418240 B = 10 GB but diskspace consumed = 11049082274 B = 10.29 GB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1147)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:979)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:938)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:504)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:771)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:259)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1865)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /dataspace/team7 is exceeded: quota = 10737418240 B = 10 GB but diskspace consumed = 11049082274 B = 10.29 GB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1147)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:979)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:938)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:504)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:771)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:259)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1078)
	... 3 more

[17:18:24] INFO mapreduce.Job: Task Id : attempt_1667571544727_0239_m_000000_1, Status : FAILED
Error: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /dataspace/team7 is exceeded: quota = 10737418240 B = 10 GB but diskspace consumed = 11049082274 B = 10.29 GB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1147)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:979)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:938)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:504)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:771)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:259)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1865)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /dataspace/team7 is exceeded: quota = 10737418240 B = 10 GB but diskspace consumed = 11049082274 B = 10.29 GB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1147)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:979)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:938)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:504)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:771)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:259)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1078)
	... 3 more

[17:18:24] INFO mapreduce.Job: Task Id : attempt_1667571544727_0239_m_000000_2, Status : FAILED
Error: org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /dataspace/team7 is exceeded: quota = 10737418240 B = 10 GB but diskspace consumed = 11049082274 B = 10.29 GB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1147)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:979)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:938)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:504)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:771)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:259)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1865)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1668)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /dataspace/team7 is exceeded: quota = 10737418240 B = 10 GB but diskspace consumed = 11049082274 B = 10.29 GB
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)
	at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1147)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:979)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:938)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:504)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:771)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:259)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:510)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1078)
	... 3 more

[17:18:24] INFO mapreduce.Job:  map 100% reduce 0%
[17:18:24] INFO mapreduce.Job: Job job_1667571544727_0239 failed with state FAILED due to: Task failed task_1667571544727_0239_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

[17:18:24] INFO mapreduce.Job: Counters: 8
	Job Counters
		Failed map tasks=4
		Launched map tasks=4
		Other local map tasks=4
		Total time spent by all maps in occupied slots (ms)=376110
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=125370
		Total vcore-milliseconds taken by all map tasks=125370
		Total megabyte-milliseconds taken by all map tasks=385136640
Job ended: Sat Nov 05 20:14:41 CST 2022
The job took 142 seconds.

[17:18:24] Type         Date       Time     Input_data_size      Duration(s)          Throughput(bytes/s)  Throughput/node     
HadoopWordcount 2022-10-11 21:38:49 33884                26.701               1269                 317                 
HadoopTerasort 2022-10-11 21:55:20 12800000             26.716               479113               119778              
HadoopWordcount 2022-10-11 22:05:17 33884                28.481               1189                 297                 
HadoopWordcount 2022-10-11 22:08:12 33884                27.705               1223                 305                 
HadoopWordcount 2022-10-11 22:09:11 33884                28.583               1185                 296                 
HadoopTerasort 2022-10-11 22:12:50 12800000             28.860               443520               110880              
HadoopTerasort 2022-10-11 22:14:45 12800000             25.854               495087               123771              
HadoopWordcount 2022-11-05 15:13:42 34017                27.391               1241                 310                 
HadoopWordcount 2022-11-05 15:23:33 34017                26.438               1286                 321                 
HadoopTerasort 2022-11-05 15:54:14 12800000             25.134               509270               127317              
HadoopWordcount 2022-11-05 15:54:49 35082                25.841               1357                 339                 
HadoopPagerank 2022-11-05 15:55:43 10712                45.624               234                  58                  
HadoopTerasort 2022-11-05 15:56:19 12800000             26.856               476616               119154              
HadoopWordcount 2022-11-05 15:56:54 35082                26.531               1322                 330                 
HadoopPagerank 2022-11-05 15:57:52 10712                48.448               221                  55                  
HadoopTerasort 2022-11-05 15:58:28 12800000             27.463               466081               116520              
HadoopWordcount 2022-11-05 15:59:03 35082                26.575               1320                 330                 
HadoopPagerank 2022-11-05 16:00:03 10712                50.887               210                  52                  
HadoopTerasort 2022-11-05 16:00:38 12800000             26.454               483858               120964              
HadoopPagerank 2022-11-05 16:11:04 10712                49.800               215                  53                  
HadoopTerasort 2022-11-05 16:25:55 12800000             28.410               450545               112636              
HadoopWordcount 2022-11-05 16:26:31 33394                26.690               1251                 312                 
HadoopPagerank 2022-11-05 16:27:30 10797                50.513               213                  53                  
HadoopTerasort 2022-11-05 16:28:10 12800000             27.707               461977               115494              
HadoopWordcount 2022-11-05 16:28:45 33394                26.312               1269                 317                 
HadoopPagerank 2022-11-05 16:29:42 10797                47.712               226                  56                  
HadoopTerasort 2022-11-05 16:30:22 12800000             27.873               459225               114806              
HadoopWordcount 2022-11-05 16:30:57 33394                26.426               1263                 315                 
HadoopPagerank 2022-11-05 16:31:57 10797                50.439               214                  53                  
HadoopTerasort 2022-11-05 16:32:36 12800000             27.500               465454               116363              
HadoopWordcount 2022-11-05 16:33:11 33394                26.692               1251                 312                 
HadoopPagerank 2022-11-05 16:34:10 10797                49.827               216                  54                  
HadoopTerasort 2022-11-05 16:34:51 12800000             28.533               448603               112150              
HadoopWordcount 2022-11-05 16:35:26 33394                26.444               1262                 315                 
HadoopPagerank 2022-11-05 16:36:25 10797                50.458               213                  53                  
HadoopTerasort 2022-11-05 16:37:05 12800000             27.716               461827               115456              
HadoopWordcount 2022-11-05 16:37:40 33394                26.574               1256                 314                 
HadoopPagerank 2022-11-05 16:38:40 10797                50.584               213                  53                  
HadoopTerasort 2022-11-05 16:39:19 12800000             27.525               465031               116257              
HadoopWordcount 2022-11-05 16:39:54 33394                26.661               1252                 313                 
HadoopPagerank 2022-11-05 16:40:53 10797                50.354               214                  53                  
HadoopTerasort 2022-11-05 16:41:33 12800000             27.766               460995               115248              
HadoopWordcount 2022-11-05 16:42:08 33394                26.514               1259                 314                 
HadoopPagerank 2022-11-05 16:43:07 10797                49.355               218                  54                  
HadoopTerasort 2022-11-05 16:43:47 12800000             28.698               446024               111506              
HadoopWordcount 2022-11-05 16:44:22 33394                26.402               1264                 316                 
HadoopPagerank 2022-11-05 16:45:22 10797                50.421               214                  53                  
HadoopTerasort 2022-11-05 16:46:02 12800000             27.822               460067               115016              
HadoopWordcount 2022-11-05 16:46:37 33394                26.300               1269                 317                 
HadoopPagerank 2022-11-05 16:47:33 10797                47.625               226                  56                  
HadoopTerasort 2022-11-05 16:48:12 12800000             26.523               482600               120650              
HadoopWordcount 2022-11-05 16:48:47 33394                26.393               1265                 316                 
HadoopPagerank 2022-11-05 16:49:45 10797                49.789               216                  54                  
HadoopTerasort 2022-11-05 16:50:26 12800000             28.572               447991               111997              
HadoopWordcount 2022-11-05 16:51:01 33394                26.744               1248                 312                 
HadoopPagerank 2022-11-05 16:52:00 10797                49.734               217                  54                  
HadoopTerasort 2022-11-05 16:52:39 12800000             27.302               468830               117207              
HadoopWordcount 2022-11-05 16:53:12 33394                24.378               1369                 342                 
HadoopPagerank 2022-11-05 16:54:09 10797                47.538               227                  56                  
HadoopTerasort 2022-11-05 16:54:50 12800000             28.844               443766               110941              
HadoopWordcount 2022-11-05 16:55:25 33394                26.420               1263                 315                 
HadoopPagerank 2022-11-05 16:56:23 10797                49.712               217                  54                  
HadoopTerasort 2022-11-05 16:57:03 12800000             27.934               458222               114555              
HadoopWordcount 2022-11-05 16:57:39 33394                26.610               1254                 313                 
HadoopPagerank 2022-11-05 16:58:38 10797                50.493               213                  53                  
HadoopTerasort 2022-11-05 16:59:18 12800000             27.546               464677               116169              
HadoopWordcount 2022-11-05 16:59:54 33394                27.289               1223                 305                 
HadoopPagerank 2022-11-05 17:00:54 10797                51.290               210                  52                  
HadoopTerasort 2022-11-05 17:03:24 320000000            31.696               10095911             2523977             
HadoopWordcount 2022-11-05 17:04:08 325830789            35.322               9224584              2306146             
HadoopPagerank 2022-11-05 17:06:40 1813330              142.520              12723                3180                
HadoopTerasort 2022-11-05 17:07:22 320000000            30.683               10429227             2607306             
HadoopWordcount 2022-11-05 17:08:06 325830789            35.450               9191277              2297819             
HadoopPagerank 2022-11-05 17:10:45 1813330              150.593              12041                3010                
HadoopTerasort 2022-11-05 17:11:29 320000000            31.755               10077153             2519288             
HadoopWordcount 2022-11-05 17:12:15 325830789            37.442               8702280              2175570             
HadoopPagerank 2022-11-05 17:14:44 1813330              139.764              12974                3243                
HadoopTerasort 2022-11-05 17:15:26 320000000            31.024               10314595             2578648             
HadoopWordcount 2022-11-05 17:16:15 325830789            39.638               8220162              2055040             
HadoopPagerank 2022-11-05 17:18:50 1813330              146.257              12398                3099                
HadoopTerasort 2022-11-05 17:19:35 320000000            33.735               9485697              2371424             
HadoopWordcount 2022-11-05 17:20:22 325830789            37.820               8615303              2153825             
HadoopPagerank 2022-11-05 17:22:55 1813330              144.454              12552                3138                
HadoopTerasort 2022-11-05 17:23:38 320000000            30.784               10395010             2598752             
HadoopWordcount 2022-11-05 17:24:24 325830789            37.374               8718113              2179528             
HadoopPagerank 2022-11-05 17:26:52 1813330              139.613              12988                3247                
HadoopTerasort 2022-11-05 17:27:35 320000000            31.550               10142630             2535657             
HadoopWordcount 2022-11-05 17:28:22 325830789            37.565               8673786              2168446             
HadoopPagerank 2022-11-05 17:31:02 1813330              151.612              11960                2990                
HadoopTerasort 2022-11-05 17:31:46 320000000            31.962               10011889             2502972             
HadoopWordcount 2022-11-05 17:32:34 325830789            38.620               8436840              2109210             
HadoopPagerank 2022-11-05 17:35:07 1813330              144.772              12525                3131                
HadoopTerasort 2022-11-05 17:35:52 320000000            32.584               9820770              2455192             
HadoopWordcount 2022-11-05 17:36:37 325830789            36.520               8921982              2230495             
HadoopPagerank 2022-11-05 17:39:10 1813330              144.621              12538                3134                
HadoopTerasort 2022-11-05 17:39:54 320000000            31.110               10286081             2571520             
HadoopWordcount 2022-11-05 17:40:43 325830789            40.584               8028552              2007138             
HadoopPagerank 2022-11-05 17:43:17 1813330              144.721              12529                3132                
HadoopTerasort 2022-11-05 17:44:02 320000000            32.924               9719353              2429838             
HadoopWordcount 2022-11-05 17:44:46 325830789            35.494               9179883              2294970             
HadoopPagerank 2022-11-05 17:47:23 1813330              148.523              12209                3052                
HadoopTerasort 2022-11-05 17:48:05 320000000            29.810               10734652             2683663             
HadoopWordcount 2022-11-05 17:48:54 325830789            39.617               8224519              2056129             
HadoopPagerank 2022-11-05 17:51:34 1813330              151.576              11963                2990                
HadoopTerasort 2022-11-05 17:52:17 320000000            31.592               10129146             2532286             
HadoopWordcount 2022-11-05 17:53:06 325830789            39.469               8255359              2063839             
HadoopPagerank 2022-11-05 17:55:37 1813330              142.820              12696                3174                
HadoopTerasort 2022-11-05 17:56:22 320000000            33.161               9649889              2412472             
HadoopWordcount 2022-11-05 17:57:08 325830789            36.578               8907835              2226958             
HadoopPagerank 2022-11-05 17:59:39 1813330              142.426              12731                3182                
HadoopTerasort 2022-11-05 18:00:23 320000000            31.854               10045834             2511458             
HadoopWordcount 2022-11-05 18:01:11 325830789            39.654               8216845              2054211             
HadoopPagerank 2022-11-05 18:03:47 1813330              146.474              12379                3094                
HadoopTerasort 2022-11-05 18:04:30 320000000            31.883               10036696             2509174             
HadoopWordcount 2022-11-05 18:05:18 325830789            39.368               8276539              2069134             
HadoopPagerank 2022-11-05 18:07:51 1813330              143.337              12650                3162                
HadoopTerasort 2022-11-05 18:11:51 800000000            44.752               17876296             4469074             
HadoopWordcount 2022-11-05 20:16:03 0                    19.510               0                    0                   